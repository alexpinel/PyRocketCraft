# (c) Jan Zwiener (jan@zwiener.org)
#
# Imitate the MPCPolicy controller with a neural network
#
# This controller is very simple: load the trained network
# data (generated by expert_train.py) and just run
# inference on the input to the step() function, i.e.
# based on the supplied state, calculate a control input (u)
# vector / action vector.

from basecontrol import BaseControl
from nnpolicynetwork import NNPolicyNetwork

import numpy as np
import torch
import torch.nn as nn

class NNPolicy(BaseControl):
    def __init__(self, network_file="torch_nn_mpc-rocket-v2.pth"):
        super().__init__()

        input_size = 16
        output_size = 5
        self.model = NNPolicyNetwork(input_size, output_size)
        self.model.load_state_dict(torch.load(network_file))

        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.model = self.model.to(device)
        self.model.eval()  # Set the model to inference mode

    def get_name(self):
        return "NN"

    def next(self, observation):
        device = next(self.model.parameters()).device
        state_tensor = torch.tensor(observation, dtype=torch.float32).to(device)
        state_tensor = state_tensor.unsqueeze(0)

        with torch.no_grad():  # Disables gradient calculation
            action_pred = self.model(state_tensor)

        # If the model is on GPU, move the result back to CPU for numpy conversion
        action = action_pred.cpu().numpy()
        predictedX = np.ndarray((0, 0))

        return action.ravel(), predictedX
